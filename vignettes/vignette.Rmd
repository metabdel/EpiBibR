---
title: "vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(EpiBibR)
```

# Overview

EpiBibR stands for "epidemiology-based bibliography for R." The R package is under the MIT License and as such is a free resource based on the open science principles (reproducible research, open data, open code). The resource may be used by researchers, whose domain is scientometrics, but also by researchers from other disciplines. For instance, the scientific community in Artificial Intelligence and Data Science may use this package to accelerate new research insights about covid-19. The package follows the methodology put in place by the Allen Institute and its partners to create the CORD-19 dataset with some differences. The later is accessible through downloads of sub-sets or through a REST API. The data provide important information such as authors, methods, data, and citations to make it easier for researchers to find relevant contributions to their research questions. Our package proposes 22 features for the 51,539 references (on June 26, 2020) and access to the data has been made as easy as possible in order to integrate efficiently in almost any researcher's pipeline.

Through this package, a researcher can connect the data to her analysis based on the R language. With this workflow in mind, a researcher can save time on collecting data, and can use a very accessible language to perform complex analytical tasks, be it R or Python for instance. Indeed, it is usual that researchers use multiple languages (functional or not) to produce certain outputs. This workflow opens these data to analyses from the largest spectrum of potential options, enhancing multidisciplinary approaches applied to these data (biostatistics, bibliometrics, text mining, etc.).

The goal of this package in this emergency context is to limit the references to the medical domain, hence limiting ourselves to the Pubmed repository, but then to leverage the methodologies used across different disciplines. As we will address this point later, a further extension could be to add references from other disciplines to not only benefit from the wealth of methodologies but also from their own theories and concepts. For instance, to assess the spread of the disease, the literature - and theories - from researchers in demography would certainly be relevant.

# Functionality

The references were collected via PubMed, a free resource that is developed and maintained by the National Center for Biotechnology Information (NCBI), at the U.S. National Library of Medicine (NLM), located at the National Institutes of Health (NIH). PubMed includes over 30 million citations from biomedical literature.

More specifically, to collect our references, we adopted the procedure used by the Allen Institute for AI for their CORD-19 project. We apply a similar query on PubMed: “COVID-19” OR Coronavirus OR “Corona virus” OR “2019-nCoV” OR “SARS-CoV” OR “MERS-CoV” OR “Severe Acute Respiratory Syndrome” OR “Middle East Respiratory Syndrome” to build our own bibliographic data.

To navigate through our dataset, EpiBibR relies on a set of search arguments: author, author’s country of origin, keyword in the title, keyword in the abstract, year and the name of the journal. Each of them can truly help scientists and R users to filter references and find the relevant articles.

In an effort to simplify the workflow between our package and the research methodologies, the format of our dataframe has been designed to integrate with different data pipelines, notably to facilitate the use of the R package Bibliometrix with our data (Aria and Cuccurullo 2017).


## Features

<center>
Table 1. Features accessible through the package.
</center>

| Field Tags | Descriptions                        | Field Tags |  Descriptions              |
|------------|-------------------------------------|------------|----------------------------|
| AU         | Authors                             | ISSN       | Source Code                |
| TI         | Document Title                      | VOL        | Volume                     |
| AB         | Abstract                            | ISSUE      | Issue Number               |
| PY         | Year                                | LT         | Language                   |
| DT         | Document Type                       | C1         | Author Address             |
| MESH       | Medical Subject Headings Vocabulary | RP         | Reprint Address            |
| TC         | Times Cited                         | ID         | PubMed ID                  |
| SO         | Publication Name (or Source)        | DE         | Authors’ Keywords          |
| J9         | Source Abbreviation                 | UT         | Unique Article Identifier  |
| JI         | ISO Source Abbreviation             | AU\_CO     | Author’s Country of Origin |
| DI         | Digital Object Identifier (DOI)     | DB         | Bibliographic Database     |





# Practical usage

## Quick start

First, install EpiBibR:

```{r, eval=FALSE}
devtools::install_github("warint/EpiBibR")
```

Next, call EpiBibR to make sure everything is installed correctly.

```{r}
library(EpiBibR)
```


## How-To 

EpiBibR allows you to search bibligraphic references using several arguments : Author, author's country of origin, author + year, keywords in the title, keywords in the abstract, year and source name.

### Retrieve bibliographic data

To get the entire bibliographic dataframe contaning around 28 000 references, use the `EpiBib_reference` function.

```{r,eval=FALSE}
EpiBib_data <- EpiBib_references()
```

### Search by author

It can be truly helpful to search references by the name of the author. For example, we will search all the articles writtin by Philippe Colson.

```{r,eval=FALSE}
colson_articles <- EpiBib_author("Colson")
```

### Search by author's country of origin.

```{r,eval=FALSE}
canada_articles <- EpiBib_country("canada")
```

### Search by author and year

```{r,eval=FALSE}
yang2019 <- EpiBib_AU_YE(author = "yang", year = 2019)
```

### Search by keywords in title

```{r,eval=FALSE}
covid_articles <- EpiBib_title("covid")
```

### Search by keywords in the abstract

```{r,eval=FALSE}
coronavirus_articles <- EpiBib_abstract("coronavirus")
```

### Search by year

```{r,eval=FALSE}
A2020_articles <- EpiBib_year(2020)
```

### Search by source

```{r,eval=FALSE}
bio_articles <- EpiBib_source("bio")
```

## Bibliometric Analysis

The *Bibliometrix* package allows a thorough bibliometric analysis using R. Our EpiBib data have been designed to integrate easily with the *Bibliometrix* package. A shinyapp is also available `biblioshiny()`..

### Biblioshiny

The [biblioshiny](https://bibliometrix.org/Biblioshiny.html) function has been developed to assist people in their bibliometric analysis. By its user-friendly interface, biblioshiny facilitates the use of Bibliometrix's main analysis tools and allows the creation of graphs and visuals.

### Biblioshiny : Procedure and Examples

This procedure is based on the one made by the creators of the Bibliometrix package (Aria and Cuccurullo 2017).

Step 1 - Load the Bibliometrix package and load the biblioshiny function

```{r,eval=FALSE}
library(bibliometrix)
biblioshiny()
```

Step 2 - Download an example at the following [link](https://www.bibliometrix.org/datasets/joi.zip) . It includes all articles published by the Journal of Informetrics from 2007 to 2017.

Step 2 - In the Load menu, select 'Web of Knowledge' as database and 'Plaintext' as file format.

Step 3 - Choose and load the file joi.zip using the browse button.

Step 4 - Try the shiny app to create analytics and plots for three different level metrics and analysis of three structures of Knowledge (K-structures).

### An Algorithmic Systematic Literature Review of EpiBib

By using Bibliometrix tools to analyse our EpiBib's data, we were able to propose a simple count of the references on the coronaviruses literature and even upgrade the original visuals.



```{r,eval=FALSE}
# Load the packages
library(EpiBibR)
library(bibliometrix)

# Load EpiBib's data
MM<-EpiBib_references()

# Only fo 2020
M<-EpiBib_year(2020)

# Summary bibliometric results
results <- biblioAnalysis(MM, sep = ";")
S <- summary(object = results, k = 10, pause = FALSE)
```

Summary includes info such as the number of documents, the most productive authors, the most productive countries and the count of articles per year. To assist in understanding this summary, we have created these three grapics.

```{r,eval=FALSE}
# Most Productive Authors

library(bibliometrix)
library(reshape2)
library(ggplot2)
library(ggsci)
library(tidyverse)
library(plyr)
library(ggthemes)
library(cowplot)

df <- plyr::ldply(S, data.frame)
df <- subset(df, .id == "MostProdAuthors", select = c(Articles, Authors.......))
df <- df %>% dplyr::rename(Authors = Authors.......)

df$Articles <- as.numeric(df$Articles)
df$Authors <-as.factor(df$Authors)

p1 <- ggplot(df, aes(x = reorder(Authors, Articles), y = Articles, fill = Articles)) +
  geom_bar(stat="identity") +
  coord_flip() +
  labs(x = "Authors") +
  theme_hc()

rm(df)

# Most Productive Countries

df <- plyr::ldply(S, data.frame)
df <- subset(df, .id == "MostProdCountries", select = c(Articles, Country))

df$Articles <- as.numeric(df$Articles)
df$Country <-as.factor(df$Country)

p2 <- ggplot(df, aes(x = reorder(Country, Articles), y = Articles, fill = Articles)) +
  geom_bar(stat="identity") +
  coord_flip() +
  labs(x = "Countries") +
  theme_hc()

rm(df)

# Count of articles per year

df <- plyr::ldply(S, data.frame)
df <- subset(df, .id == "AnnualProduction", select = c(Year..., Articles))
df <- df %>% dplyr::rename(Year = Year...)

df$Year <- as.numeric(as.character(df$Year))
df$Articles <- as.numeric(df$Articles)


p3 <- ggplot(df, aes(x = Year, y = Articles, colour = cond)) +
  geom_line(colour = "#0072B2") +
  geom_point(colour = "#0072B2") +
  labs( x = "") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_x_continuous(breaks = seq(1950,2020, 5)) +
  theme_hc()

rm(df)
```

```{r, fig.cap = "(A) Count of Articles, (B) Most Productive Authors and (C) Most Productive Countries", out.width = '70%',eval=FALSE}

ggdraw() +
  draw_plot(p3, 0, .5, 1, .5) +
  draw_plot(p1, 0, 0, .5, .5) +
  draw_plot(p2, .5, 0, .5, .5) +
  draw_plot_label(c("A", "B", "C"), c(0, 0, 0.5), c(1, 0.5, 0.5), size = 15)


```

```{r, eval = TRUE, fig.cap ="(A) Count of Articles, (B) Most Productive Authors and (C) Most Productive Countries", out.width = '70%', echo=FALSE}
knitr::include_graphics("./figure1.png")

```


We can also use powerful techniques such as Social Network Theory to find potential clusters of topics, clusters of researchers and clusters of country collaborations. The U.S. and China produce the bulk of the research on coronaviruses.

```{r,eval=FALSE}
# Country Collaboration Network
M <- metaTagExtraction(M, Field = "AU_CO", sep = ";")
NetMatrix <- biblioNetwork(M, analysis = "collaboration", network = "countries", sep = ";")

# Plot the network

net1 = networkPlot(NetMatrix, n = dim(NetMatrix)[1], Title = "", type = "sphere", size=TRUE, remove.multiple=FALSE, labelsize=3, cluster="none")
```
```{r,echo=FALSE, eval = TRUE, fig.cap = "Country Collaboration Network", out.width = '60%'}
knitr::include_graphics("./figure5.png")
```

#### To go further 

- [A shiny app by Bibliometrix](https://bibliometrix.org/Biblioshiny.html)
- [biblioshiny tutorial](https://www.bibliometrix.org/biblioshiny/assets/player/KeynoteDHTMLPlayer.html#0)
- [Bibliometrics (17): The Biblioshiny App For Non-Coders | Bibliometrix R Package (video)](https://www.youtube.com/watch?v=9YwVhFEovCA&feature=youtu.be)
- [Bibliometrics](https://bibliometrix.org/index.html)
         

 



